# EEGIntentPaper

Description:
This repository contains the code and models used for the paper titled:

TransNN-MHA: A Transformer-Based Model to Distinguish Real and Imaginary Motor Intent for Assistive Robotics.

The study focuses on distinguishing real and imagined motor intentions using EEG data, with applications in assistive robotics.
Dataset

The dataset used in this research is publicly available at Physionet's EEG Motor Movement/Imagery Dataset(https://physionet.org/content/eegmmidb/1.0.0/).
This dataset contains EEG data for real and imagined motor movements that were used to train and test the models in this project.

Project Structure

    All Models:
    Contains the implementation of various models used in the research, including the TransNN-MHA model.

    Data Augmentation:
    Scripts used for augmenting EEG data to enhance model training.

    Statistical Analysis:
    Code for statistical tests and evaluations performed on the results.
